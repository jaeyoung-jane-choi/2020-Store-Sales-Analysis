{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/janechoi/Desktop/연구학점/credit card/data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>three_month</th>\n",
       "      <th>four_month</th>\n",
       "      <th>five_month</th>\n",
       "      <th>six_month</th>\n",
       "      <th>seven_month</th>\n",
       "      <th>eight_month</th>\n",
       "      <th>nine_month</th>\n",
       "      <th>ten_month</th>\n",
       "      <th>eleven_month</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>13.484583</td>\n",
       "      <td>13.584839</td>\n",
       "      <td>13.280465</td>\n",
       "      <td>13.543514</td>\n",
       "      <td>13.454541</td>\n",
       "      <td>13.635700</td>\n",
       "      <td>13.707766</td>\n",
       "      <td>13.678053</td>\n",
       "      <td>13.820498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>12.034267</td>\n",
       "      <td>11.984267</td>\n",
       "      <td>11.772539</td>\n",
       "      <td>11.657644</td>\n",
       "      <td>11.624978</td>\n",
       "      <td>11.679045</td>\n",
       "      <td>11.412316</td>\n",
       "      <td>11.679650</td>\n",
       "      <td>12.001505</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.682157</td>\n",
       "      <td>11.946561</td>\n",
       "      <td>12.104673</td>\n",
       "      <td>11.982929</td>\n",
       "      <td>12.198904</td>\n",
       "      <td>11.605635</td>\n",
       "      <td>11.869600</td>\n",
       "      <td>11.786219</td>\n",
       "      <td>11.324873</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>13.781510</td>\n",
       "      <td>13.864437</td>\n",
       "      <td>13.443204</td>\n",
       "      <td>13.883036</td>\n",
       "      <td>13.664189</td>\n",
       "      <td>13.544639</td>\n",
       "      <td>13.749829</td>\n",
       "      <td>13.456588</td>\n",
       "      <td>13.552753</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>12.037654</td>\n",
       "      <td>12.135803</td>\n",
       "      <td>11.703192</td>\n",
       "      <td>11.902068</td>\n",
       "      <td>12.112233</td>\n",
       "      <td>12.262318</td>\n",
       "      <td>12.355108</td>\n",
       "      <td>12.481809</td>\n",
       "      <td>12.977833</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34908</th>\n",
       "      <td>2018</td>\n",
       "      <td>10.931831</td>\n",
       "      <td>11.032583</td>\n",
       "      <td>10.998522</td>\n",
       "      <td>10.798117</td>\n",
       "      <td>11.124739</td>\n",
       "      <td>10.927735</td>\n",
       "      <td>10.491274</td>\n",
       "      <td>10.889304</td>\n",
       "      <td>11.225243</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34909</th>\n",
       "      <td>2018</td>\n",
       "      <td>13.169520</td>\n",
       "      <td>13.532389</td>\n",
       "      <td>13.538250</td>\n",
       "      <td>13.415886</td>\n",
       "      <td>13.751962</td>\n",
       "      <td>13.720258</td>\n",
       "      <td>13.464331</td>\n",
       "      <td>13.272137</td>\n",
       "      <td>13.829484</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34911</th>\n",
       "      <td>2018</td>\n",
       "      <td>11.709712</td>\n",
       "      <td>11.854487</td>\n",
       "      <td>12.253842</td>\n",
       "      <td>12.283695</td>\n",
       "      <td>11.189369</td>\n",
       "      <td>12.411343</td>\n",
       "      <td>12.054419</td>\n",
       "      <td>12.656466</td>\n",
       "      <td>12.832393</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34912</th>\n",
       "      <td>2018</td>\n",
       "      <td>13.246602</td>\n",
       "      <td>12.990952</td>\n",
       "      <td>13.479238</td>\n",
       "      <td>13.266587</td>\n",
       "      <td>13.006151</td>\n",
       "      <td>13.056834</td>\n",
       "      <td>13.003419</td>\n",
       "      <td>13.242303</td>\n",
       "      <td>13.165149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34913</th>\n",
       "      <td>2018</td>\n",
       "      <td>14.016245</td>\n",
       "      <td>14.286630</td>\n",
       "      <td>14.662666</td>\n",
       "      <td>14.601432</td>\n",
       "      <td>14.602798</td>\n",
       "      <td>14.670807</td>\n",
       "      <td>14.520410</td>\n",
       "      <td>14.445642</td>\n",
       "      <td>14.869673</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34794 rows × 1990 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  three_month  four_month  five_month  six_month  seven_month  \\\n",
       "0      2017    13.484583   13.584839   13.280465  13.543514    13.454541   \n",
       "1      2017    12.034267   11.984267   11.772539  11.657644    11.624978   \n",
       "2      2017    10.682157   11.946561   12.104673  11.982929    12.198904   \n",
       "3      2017    13.781510   13.864437   13.443204  13.883036    13.664189   \n",
       "4      2017    12.037654   12.135803   11.703192  11.902068    12.112233   \n",
       "...     ...          ...         ...         ...        ...          ...   \n",
       "34908  2018    10.931831   11.032583   10.998522  10.798117    11.124739   \n",
       "34909  2018    13.169520   13.532389   13.538250  13.415886    13.751962   \n",
       "34911  2018    11.709712   11.854487   12.253842  12.283695    11.189369   \n",
       "34912  2018    13.246602   12.990952   13.479238  13.266587    13.006151   \n",
       "34913  2018    14.016245   14.286630   14.662666  14.601432    14.602798   \n",
       "\n",
       "       eight_month  nine_month  ten_month  eleven_month  ...  month_3 month_4  \\\n",
       "0        13.635700   13.707766  13.678053     13.820498  ...        0       0   \n",
       "1        11.679045   11.412316  11.679650     12.001505  ...        0       0   \n",
       "2        11.605635   11.869600  11.786219     11.324873  ...        0       0   \n",
       "3        13.544639   13.749829  13.456588     13.552753  ...        0       0   \n",
       "4        12.262318   12.355108  12.481809     12.977833  ...        0       0   \n",
       "...            ...         ...        ...           ...  ...      ...     ...   \n",
       "34908    10.927735   10.491274  10.889304     11.225243  ...        0       0   \n",
       "34909    13.720258   13.464331  13.272137     13.829484  ...        0       0   \n",
       "34911    12.411343   12.054419  12.656466     12.832393  ...        0       0   \n",
       "34912    13.056834   13.003419  13.242303     13.165149  ...        0       0   \n",
       "34913    14.670807   14.520410  14.445642     14.869673  ...        0       0   \n",
       "\n",
       "       month_5  month_6  month_7  month_8  month_9  month_10  month_11  \\\n",
       "0            0        1        0        0        0         0         0   \n",
       "1            0        1        0        0        0         0         0   \n",
       "2            0        1        0        0        0         0         0   \n",
       "3            0        1        0        0        0         0         0   \n",
       "4            0        1        0        0        0         0         0   \n",
       "...        ...      ...      ...      ...      ...       ...       ...   \n",
       "34908        0        0        0        0        0         0         1   \n",
       "34909        0        0        0        0        0         0         1   \n",
       "34911        0        0        0        0        0         0         1   \n",
       "34912        0        0        0        0        0         0         1   \n",
       "34913        0        0        0        0        0         0         1   \n",
       "\n",
       "       month_12  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "34908         0  \n",
       "34909         0  \n",
       "34911         0  \n",
       "34912         0  \n",
       "34913         0  \n",
       "\n",
       "[34794 rows x 1990 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading dataset \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"colorblind\")\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \n",
    "    data = pd.read_csv(data_dir)\n",
    "\n",
    "\n",
    "    #make amount into log value  :: when predicting use np.expm1(amount) to make it back to original amount size\n",
    "    data['amount'] = np.log(data[\"amount\"]) #log0 error 방지 \n",
    "    data['three_month'] = np.log(data[\"three_month\"])\n",
    "    data['four_month'] = np.log(data[\"four_month\"])\n",
    "    data['five_month'] = np.log(data[\"five_month\"])\n",
    "    data['six_month'] = np.log(data[\"six_month\"])\n",
    "    data['seven_month'] = np.log(data[\"seven_month\"])\n",
    "    data['eight_month'] = np.log(data[\"eight_month\"])\n",
    "    data['nine_month'] = np.log(data[\"nine_month\"])\n",
    "    data['ten_month'] = np.log(data[\"ten_month\"])\n",
    "    data['eleven_month'] = np.log(data[\"eleven_month\"])\n",
    "    data['twelve_month'] = np.log(data[\"twelve_month\"])\n",
    "    \n",
    "    \n",
    "    #drop store 795\n",
    "    l = data.loc[(data.store_id == 795)].index\n",
    "    data.drop(index=l, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #make values to category \n",
    "    data['store_id'] = data['store_id'].astype('category')\n",
    "    data['month'] = data['month'].astype('category')\n",
    "    \n",
    "    #delete category and use train test split to split dataset \n",
    "    test = data[data['category']== 'test']\n",
    "    data =data[data['category']!= 'test']\n",
    "    \n",
    "    del data['category']\n",
    "    del test['category']\n",
    "    \n",
    "    \n",
    "    data.sort_values(by=['year','month','store_id'], inplace=True)\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    \n",
    "    data['category'] = 'train'\n",
    "    \n",
    "    for row in data['store_id'].value_counts().index:\n",
    "#     print(row)\n",
    "        k = data.loc[data['store_id'] == row ]\n",
    "        k.iloc[-3:,14] ='val'\n",
    "        data.loc[data['store_id'] == row ] = k\n",
    "        \n",
    "    \n",
    "    \n",
    "    train = data[data['category']=='train']\n",
    "    val = data[data['category']=='val']\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, y_train = train[['store_id', 'year', 'month', 'three_month', \n",
    "              'four_month','five_month','six_month', \n",
    "              'seven_month', 'eight_month', 'nine_month', \n",
    "              'ten_month','eleven_month','twelve_month']], train['amount']\n",
    "    \n",
    "   \n",
    "    X_train['ID_STORE'] = X_train['store_id'].copy()\n",
    "    \n",
    "    X_train = pd.get_dummies(X_train, columns = ['store_id']) \n",
    "    \n",
    "    X_train = pd.get_dummies(X_train, columns = ['month']) \n",
    "    \n",
    "    \n",
    "    X_val, y_val = val[['store_id', 'year', 'month', 'three_month', \n",
    "              'four_month','five_month','six_month', \n",
    "              'seven_month', 'eight_month', 'nine_month', \n",
    "              'ten_month','eleven_month','twelve_month']], val['amount']\n",
    "    \n",
    "    \n",
    "    X_val['ID_STORE'] = X_val['store_id'].copy()\n",
    "    \n",
    "    X_val = pd.get_dummies(X_val, columns = ['store_id']) \n",
    "    X_val = pd.get_dummies(X_val, columns = ['month']) \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, X_val, y_train, y_val,test \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######NEWNEWNEWNENW########## \n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val,test = load_data('/Users/janechoi/Desktop/연구학점/credit card/data/train_na_full_month.csv')\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val,test  = load_data('/Users/janechoi/Desktop/연구학점/credit card/data/train_mean_full_month.csv')\n",
    "# \n",
    "# X_train, X_val, y_train, y_val,test  = load_data('/Users/janechoi/Desktop/연구학점/credit card/data/train_median_full_month.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val,test  = load_data('/Users/janechoi/Desktop/연구학점/credit card/data/train_spline2_full_month.csv')\n",
    "\n",
    "# X_train, X_val, y_train, y_val,test  = load_data('/Users/janechoi/Desktop/연구학점/credit card/data/train_linear_full_month.csv')\n",
    "\n",
    "X_train, X_val, y_train, y_val,test  = load_data('/Users/janechoi/Desktop/연구학점/credit card/data/train_time_full_month.csv')\n",
    "\n",
    "# X_train #17-6 ~ 18-11\n",
    "# X_val #18-12 ~ 19-2 \n",
    "\n",
    "# X_train['store_id'].value_counts().index\n",
    "# X_train.shape\n",
    "# X_train.isnull().sum()\n",
    "X_train\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for validation set is...323970.8077438762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "#FINAL\n",
    "# {'target': -332525.56286467746,\n",
    "#  'params': {'learning_rate': 0.0662145152945549,\n",
    "#   'max_depth': 10.417578787145434,\n",
    "#   'n_estimators': 647.4124413661855,\n",
    "#   'reg_alpha': 0.6229640151466079,\n",
    "#   'reg_lambda': 0.5419743630768536}}\n",
    "\n",
    "def xgb_cv(c=None,v=None):\n",
    "    \n",
    "    \n",
    "   #columns to be used \n",
    "    avoid_cols = ['amount', 'category','year','ID_STORE']\n",
    "    cols = [col for col in X_train.columns if col not in avoid_cols] #store_id, 3,6,12month, month\n",
    "    skf = list(StratifiedKFold(n_splits=5,random_state=1008).split(X_train, X_train['ID_STORE'])) \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    train = X_train[cols]\n",
    "    val = X_val[cols]\n",
    "    \n",
    "    \n",
    "    #basic parameters \n",
    "    basicparams  = {'booster' : 'gbtree',\n",
    "            'objective' :'reg:linear',\n",
    "             'eval_metric' : \"mae\",\n",
    "            'random_state' : 314,  \n",
    "            'verbosity' :2, # 0 (silent), 1 (warning), 2 (info), 3 (debug)\n",
    "             'silent' : False}\n",
    "    \n",
    "    #optimized parametes update \n",
    "#     params = xgbBO.max['params']\n",
    "    \n",
    "#     k = params['max_depth']\n",
    "#     params['max_depth'] = int(round(k))\n",
    "    \n",
    "#     k = params['n_estimators']\n",
    "#     params['n_estimators'] = int(round(k))\n",
    "    \n",
    "    \n",
    "#     k = params['learning_rate']\n",
    "#     params['learning_rate'] = k\n",
    "    \n",
    "#     k = params['reg_lambda']\n",
    "#     params['reg_lambda'] = k\n",
    "    \n",
    "#     k = params['reg_alpha']\n",
    "#     params['reg_alpha'] = k\n",
    "\n",
    "    params = {}\n",
    "    params['max_depth'] = int(round(10.4 ))\n",
    "    params['n_estimators'] = int(round(  647.4 ))\n",
    "    params['learning_rate'] = 0.0662145152945549\n",
    "    params['reg_lambda'] =  0.5419743630768536\n",
    "    params['reg_alpha'] =0.6229640151466079 \n",
    "    \n",
    "    params.update(basicparams)\n",
    "    \n",
    "    #fit on xgboost regressor \n",
    "    train_x =X_train[cols]\n",
    "    val = X_val[cols]\n",
    "    \n",
    "    res = xgb.XGBRegressor(**params)\n",
    "    res.fit(train_x, y_train ,eval_set = [(val, y_val)],verbose=False)\n",
    "    \n",
    "    #predictions \n",
    "    predictions = res.predict(X_val[cols])\n",
    "    error= mean_absolute_error( np.exp(y_val), np.exp(predictions))\n",
    "    \n",
    "    print('MAE for validation set is...' + str(error))\n",
    "\n",
    "    \n",
    "    return cols, res \n",
    "    \n",
    "\n",
    "cols,m = xgb_cv()\n",
    "\n",
    "\n",
    "#NA \n",
    "# MAE for validation set is...321279.7862807657\n",
    "# MAE for validation set is...0.39661871051850234\n",
    "\n",
    "\n",
    "#MEAN\n",
    "\n",
    "# MAE for validation set is...323330.41575841577\n",
    "\n",
    "#Median\n",
    "# MAE for validation set is...320487.3626868823\n",
    "\n",
    "#Linear\n",
    "# MAE for validation set is...323462.4362074963\n",
    "\n",
    "\n",
    "#time\n",
    "# MAE for validation set is...323970.8077438762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.352e+0\u001b[0m | \u001b[0m 0.07293 \u001b[0m | \u001b[0m 15.73   \u001b[0m | \u001b[0m 801.4   \u001b[0m | \u001b[0m 0.6635  \u001b[0m | \u001b[0m 0.5847  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-3.368e+0\u001b[0m | \u001b[0m 0.07875 \u001b[0m | \u001b[0m 11.56   \u001b[0m | \u001b[0m 945.9   \u001b[0m | \u001b[0m 0.7891  \u001b[0m | \u001b[0m 0.5767  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-3.336e+0\u001b[0m | \u001b[95m 0.06261 \u001b[0m | \u001b[95m 15.7    \u001b[0m | \u001b[95m 801.2   \u001b[0m | \u001b[95m 0.6092  \u001b[0m | \u001b[95m 0.5456  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.342e+0\u001b[0m | \u001b[0m 0.08052 \u001b[0m | \u001b[0m 8.351   \u001b[0m | \u001b[0m 872.2   \u001b[0m | \u001b[0m 0.6467  \u001b[0m | \u001b[0m 0.5776  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-3.328e+0\u001b[0m | \u001b[95m 0.04251 \u001b[0m | \u001b[95m 5.271   \u001b[0m | \u001b[95m 552.9   \u001b[0m | \u001b[95m 0.5067  \u001b[0m | \u001b[95m 0.5155  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.346e+0\u001b[0m | \u001b[0m 0.08439 \u001b[0m | \u001b[0m 7.356   \u001b[0m | \u001b[0m 955.9   \u001b[0m | \u001b[0m 0.7309  \u001b[0m | \u001b[0m 0.5169  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.338e+0\u001b[0m | \u001b[0m 0.07792 \u001b[0m | \u001b[0m 10.38   \u001b[0m | \u001b[0m 651.6   \u001b[0m | \u001b[0m 0.7338  \u001b[0m | \u001b[0m 0.615   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': -332804.8590835875,\n",
       " 'params': {'learning_rate': 0.04250609017118622,\n",
       "  'max_depth': 5.2712800522064605,\n",
       "  'n_estimators': 552.9276928776961,\n",
       "  'reg_alpha': 0.506657965585959,\n",
       "  'reg_lambda': 0.5154936496056668}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "\n",
    "#columns to be used \n",
    "avoid_cols = ['amount', 'category','year','ID_STORE']\n",
    "cols = [col for col in X_train.columns if col not in avoid_cols] #store_id, 3,6,12month, month\n",
    "skf = list(StratifiedKFold(n_splits=5,random_state=1008).split(X_train, X_train['ID_STORE'])) \n",
    "\n",
    "\n",
    "\n",
    "#USING BAYESIAN OPTIMIZATION !!!!! \n",
    "\n",
    "def xgb_eval(max_depth,learning_rate, n_estimators, reg_lambda, reg_alpha ):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train = X_train[cols]\n",
    "    val = X_val[cols]\n",
    "    \n",
    "    #select params to use \n",
    "    params = {'booster' : 'gbtree',\n",
    "            'objective' :'reg:linear',\n",
    "             'eval_metric' : \"mae\",\n",
    "            'random_state' : 314,  \n",
    "            'verbosity' :2, # 0 (silent), 1 (warning), 2 (info), 3 (debug)\n",
    "             'silent' : False,\n",
    "             'nthread':3 }\n",
    "    \n",
    "    #optimize parametes :: \n",
    "    params[\"max_depth\"] = int(round(max_depth))\n",
    "    params['learning_rate'] = learning_rate\n",
    "    params['n_estimators'] = int(round(n_estimators))\n",
    "    params['reg_lambda'] = max(reg_lambda, 0)\n",
    "    params['reg_alpha'] = max(reg_alpha, 0)\n",
    " \n",
    "\n",
    "    #use cv to get result \n",
    "    \n",
    "    res =  xgb.XGBRegressor(**params)\n",
    "    best=[]\n",
    "    #use skf for 5 fold seperatly \n",
    "    for fold_, (trn_, val_) in enumerate(skf):\n",
    "        print(\"Fold:\",fold_)\n",
    "    \n",
    "        train_x, train_y = train.iloc[trn_], y_train.iloc[trn_]\n",
    "        other_x, other_y = train.iloc[val_], y_train.iloc[val_]\n",
    "        #,early_stopping_rounds = 100 추가 안햇다...하ㅏ\n",
    "        res.fit(train_x, train_y ,eval_set = [(val, y_val)],verbose=False)\n",
    "    \n",
    "        pred= res.predict(other_x)\n",
    "        #calculate mae on other train fold \n",
    "        mae_error = mean_absolute_error(np.exp(other_y), np.exp(pred))\n",
    "    \n",
    "        best.append(mae_error)\n",
    "        \n",
    "#     print(best)\n",
    "    mean = np.mean(np.array(best))\n",
    "    \n",
    "#     print(mean)\n",
    "    return  -(mean) #maximize :: minimize minus mae \n",
    "\n",
    "\n",
    "xgbBO = BayesianOptimization(xgb_eval, {'max_depth':(5,20),\n",
    "                                        'n_estimators':(500,1000), \n",
    "                                        'learning_rate':(0.04,0.1), #default 0.3 \n",
    "                                        'reg_lambda':(0.5,0.7), \n",
    "                                        'reg_alpha' :(0.5,0.8)},\n",
    "                                        random_state= 0 )\n",
    "\n",
    "#randomly use 10 initial points, and use bayesian for 100 more rounds \n",
    "xgbBO.maximize(init_points=2, n_iter=5)  \n",
    "xgbBO.max \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-3.325e+0\u001b[0m | \u001b[95m 0.06621 \u001b[0m | \u001b[95m 10.42   \u001b[0m | \u001b[95m 647.4   \u001b[0m | \u001b[95m 0.623   \u001b[0m | \u001b[95m 0.542   \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-3.362e+0\u001b[0m | \u001b[0m 0.0603  \u001b[0m | \u001b[0m 18.4    \u001b[0m | \u001b[0m 849.3   \u001b[0m | \u001b[0m 0.618   \u001b[0m | \u001b[0m 0.5208  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.344e+0\u001b[0m | \u001b[0m 0.05262 \u001b[0m | \u001b[0m 17.4    \u001b[0m | \u001b[0m 799.2   \u001b[0m | \u001b[0m 0.6882  \u001b[0m | \u001b[0m 0.5045  \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-3.332e+0\u001b[0m | \u001b[0m 0.04017 \u001b[0m | \u001b[0m 15.74   \u001b[0m | \u001b[0m 692.6   \u001b[0m | \u001b[0m 0.6148  \u001b[0m | \u001b[0m 0.563   \u001b[0m |\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.347e+0\u001b[0m | \u001b[0m 0.05818 \u001b[0m | \u001b[0m 18.51   \u001b[0m | \u001b[0m 608.9   \u001b[0m | \u001b[0m 0.6018  \u001b[0m | \u001b[0m 0.591   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': -332525.56286467746,\n",
       " 'params': {'learning_rate': 0.0662145152945549,\n",
       "  'max_depth': 10.417578787145434,\n",
       "  'n_estimators': 647.4124413661855,\n",
       "  'reg_alpha': 0.6229640151466079,\n",
       "  'reg_lambda': 0.5419743630768536}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# {'target': -332804.8590835875,\n",
    "#  'params': {'learning_rate': 0.04250609017118622,\n",
    "#   'max_depth': 5.2712800522064605,\n",
    "#   'n_estimators': 552.9276928776961,\n",
    "#   'reg_alpha': 0.506657965585959,\n",
    "#   'reg_lambda': 0.5154936496056668}}\n",
    "\n",
    "# |   iter    |  target   | learni... | max_depth | n_esti... | reg_alpha | reg_la... |\n",
    "# |  3        | -3.336e+0 |  0.06261  |  15.7     |  801.2    |  0.6092   |  0.5456   |\n",
    "# |  5        | -3.328e+0 |  0.04251  |  5.271    |  552.9    |  0.5067   |  0.5155   |\n",
    "\n",
    "\n",
    "# params before \n",
    "# {'max_depth':(5,20),\n",
    "#           'n_estimators':(500,1000), \n",
    "#         'learning_rate':(0.04,0.1), #default 0.3 \n",
    "#   'reg_lambda':(0.5,0.7), \n",
    "#    'reg_alpha' :(0.5,0.8)}\n",
    "\n",
    "\n",
    "xgbBO.set_bounds(new_bounds= {'max_depth':(5,20),\n",
    "                                        'n_estimators':(550,850), \n",
    "                                        'learning_rate':(0.04,0.07), #default 0.3 \n",
    "                                        'reg_lambda':(0.5,0.6), \n",
    "                                        'reg_alpha' :(0.5,0.7)}\n",
    "                             )\n",
    "\n",
    "#re maximize acccording to new boundaries \n",
    "xgbBO.maximize(init_points=0, n_iter=5)\n",
    "\n",
    "xgbBO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -332525.56286467746,\n",
       " 'params': {'learning_rate': 0.0662145152945549,\n",
       "  'max_depth': 10.417578787145434,\n",
       "  'n_estimators': 647.4124413661855,\n",
       "  'reg_alpha': 0.6229640151466079,\n",
       "  'reg_lambda': 0.5419743630768536}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbBO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.377e+0\u001b[0m | \u001b[0m 0.05816 \u001b[0m | \u001b[0m 12.74   \u001b[0m | \u001b[0m 675.8   \u001b[0m | \u001b[0m 0.5663  \u001b[0m | \u001b[0m 0.5924  \u001b[0m |\n",
      "Fold: 0\n"
     ]
    }
   ],
   "source": [
    "# |   iter    |  target   | learni... | max_depth | n_esti... | reg_alpha | reg_la... |\n",
    "# |  8        | -3.325e+0 |  0.06621  |  10.42    |  647.4    |  0.623    |  0.542    |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#BEFORE PARAMS :: \n",
    "# xgbBO.set_bounds(new_bounds= {'max_depth':(5,20),\n",
    "#                                         'n_estimators':(550,850), \n",
    "#                                         'learning_rate':(0.04,0.07), #default 0.3 \n",
    "#                                         'reg_lambda':(0.5,0.6), \n",
    "#                                         'reg_alpha' :(0.5,0.7)}\n",
    "#                              )\n",
    "\n",
    "\n",
    "xgbBO.set_bounds(new_bounds= {'max_depth':(9,15),\n",
    "                                        'n_estimators':(600,700), \n",
    "                                        'learning_rate':(0.05,0.07), #default 0.3 \n",
    "                                        'reg_lambda':(0.5,0.6), \n",
    "                                        'reg_alpha' :(0.5,0.7)}\n",
    "                             )\n",
    "\n",
    "\n",
    "#re maximize acccording to new boundaries \n",
    "xgbBO.maximize(init_points=0, n_iter=5)\n",
    "\n",
    "xgbBO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBRegressor' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c75eeec24436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mgraph_for_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#{'learning_rate': 0.1, 'max_depth': 20, 'min_data_in_leaf': 50, 'num_iteration': 2500, 'num_leaves': 25}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c75eeec24436>\u001b[0m in \u001b[0;36mgraph_for_tuning\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgraph_for_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#because we use negative change to absolute values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBRegressor' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "#visualization between meantestscore and parameter individually \n",
    "\n",
    "def graph_for_tuning(model):\n",
    "    results = pd.DataFrame(model.cv_results_)\n",
    "    results = results.iloc[:,[4,5,6,7,8,15]]\n",
    "    results['mean_test_score'] = abs(results['mean_test_score']) #because we use negative change to absolute values \n",
    "\n",
    "    \n",
    "    #CHANGE NAME BEFORE EXECUTING!!!!!!! \n",
    "    results.to_csv('LGBM_NAN_3.csv', index=False)\n",
    "\n",
    "    \n",
    "    #DRAWING A PLOT!!! \n",
    "    for params in results.columns[:5]:\n",
    "        sns.lineplot(x=params , y='mean_test_score', color='blue', data=results,label= 'Mean TEST Score')\n",
    "#         sns.lineplot(x=params , y='mean_train_score', color='red', data=results, label = 'Mean Train Score')\n",
    "        plt.title('Graph for '+str(params)+' Related to TEST Score for CV')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.show()\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "results =graph_for_tuning()\n",
    "\n",
    "#{'learning_rate': 0.1, 'max_depth': 20, 'min_data_in_leaf': 50, 'num_iteration': 2500, 'num_leaves': 25}\n",
    "\n",
    "#visualization between two parameters \n",
    "def heatmap_visualization(index,columns):\n",
    "\n",
    "    pvt = pd.pivot_table(results,values='mean_test_score', index=index, columns=column)\n",
    "    ax = sns.heatmap(pvt)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "# heatmap_visualization('param_min_data_in_leaf','param_max_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.198266e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.056920e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.092159e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.670757e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.057676e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>2132</td>\n",
       "      <td>2.032808e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>2133</td>\n",
       "      <td>8.383913e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>2134</td>\n",
       "      <td>5.533323e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>2135</td>\n",
       "      <td>1.737276e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2136</td>\n",
       "      <td>6.508773e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1967 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id        amount\n",
       "0            0  2.198266e+06\n",
       "1            1  3.056920e+05\n",
       "2            2  1.092159e+06\n",
       "3            4  2.670757e+06\n",
       "4            5  1.057676e+06\n",
       "...        ...           ...\n",
       "1962      2132  2.032808e+06\n",
       "1963      2133  8.383913e+05\n",
       "1964      2134  5.533323e+05\n",
       "1965      2135  1.737276e+06\n",
       "1966      2136  6.508773e+06\n",
       "\n",
       "[1967 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a submission file \n",
    "\n",
    "# cols,m = lgbm_cv('seven_month')\n",
    "def make_submission(model, test, name):\n",
    "    \n",
    "    \n",
    "    test_pred_y = model.predict(test[cols])\n",
    "    test_pred_y = np.exp(test_pred_y)\n",
    "    test['amount'] =test_pred_y\n",
    "    \n",
    "    store= pd.DataFrame(data=[[795,0]],columns=['store_id', 'amount'])\n",
    "    test= pd.concat([test,store])\n",
    "    \n",
    "    grouped_ww = test.groupby('store_id')['amount']\n",
    "    \n",
    "    submission = pd.DataFrame(grouped_ww.sum())\n",
    "    \n",
    "\n",
    "    submission.reset_index(inplace=True)\n",
    "#     print(submission)\n",
    "    submission.to_csv(str(name)+'.csv', index=False)\n",
    "    \n",
    "    \n",
    "    return submission\n",
    "    \n",
    "sub= make_submission(m,test,'submission_na_xgboost_bay')\n",
    "\n",
    "sub\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
